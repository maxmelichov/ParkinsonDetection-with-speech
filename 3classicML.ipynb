{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#library import\n",
    "import math\n",
    "import wave\n",
    "import scipy\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import glob\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from pydub.utils import db_to_float\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.silence import detect_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir =\"wav_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df=pd.read_csv(\"recordings-diagnosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     39257\n",
       "False    22780\n",
       "Name: professional-diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[\"professional-diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id','class','duration','maximum_pitch','minmum_pitch','mean_pitch',\n",
    "'total_energy','energy_freq','power','minimum_intensity','maximum_intensity','mean_intensity','speaking_rate',\n",
    "'silences','voice_breaks','total_duration_of_pauses','number_of_pauses',\n",
    "'number_of_voice_breaks','maximum_duration_of_pauses','avg_duration_of_pauses',\n",
    "'maximum_falling','maximum_rising','jitter','shimmer','jitterrap','number_of_rising',\n",
    "'number_of_falling','avg_rise','avg_fall','zcr','chroma_stft','mfcc','root_mean_square_value','melspectogram'\n",
    ",'spectral_bandwidth','spectral_centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(files_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "save = []\n",
    "for index,file in enumerate(os.listdir(files_dir)[:5000]):\n",
    "    save.append(file[:-4])\n",
    "    save.append(label_df[\"professional-diagnosis\"].loc[label_df[\"file_name\"]==file].values[0])\n",
    "    data, sampling_rate  = librosa.core.load(os.path.join(files_dir,file))\n",
    "    Audio(data = data,rate = sampling_rate)\n",
    "    librosa.display.waveshow(data, sampling_rate)\n",
    "    # Duration : Total duration of the audio\n",
    "    total_samples = data.size\n",
    "    total_duration = int(total_samples/sampling_rate)\n",
    "    save.append(total_duration)\n",
    "    # Fourier Transform from data \n",
    "\n",
    "    fourier_transform = np.fft.rfft(data)\n",
    "\n",
    "    # Frequencies\n",
    "\n",
    "    frequencies = np.abs(fourier_transform)\n",
    "    \n",
    "    # Maximum Pitch\n",
    "\n",
    "    max_pitch = np.argmax(frequencies)\n",
    "    save.append(max_pitch)\n",
    "\n",
    "    arr = [117]*len(frequencies)\n",
    "    sum_freq = 0\n",
    "    for i in range(0,len(frequencies)):\n",
    "        if int(frequencies[i])>0 and int(frequencies[i])<int(max_pitch):\n",
    "            arr[i] = int(frequencies[i])\n",
    "            sum_freq=sum_freq + i\n",
    "    # Minmum Pitch\n",
    "    min_pitch = arr.index(min(arr))\n",
    "    save.append(min_pitch)\n",
    "    # Mean pitch\n",
    "    mean_pitch=sum_freq/len(frequencies)\n",
    "    save.append(mean_pitch)\n",
    "    #total energy\n",
    "    energy= np.sum(data**2)\n",
    "    save.append(energy)\n",
    "    energy_freq = np.sum(frequencies**2)/total_samples\n",
    "    save.append(energy_freq)\n",
    "    #power\n",
    "    power = energy / total_duration\n",
    "    save.append(power)\n",
    "    #minimum intensity\n",
    "    plt.figure(1, figsize=(9,6))\n",
    "    plt.subplot(211)\n",
    "    #IntensityMin : Minimum Intensity of the audio signal\n",
    "    Pxx, freqs, bins, im = plt.specgram(data, Fs = sampling_rate, NFFT=1024, cmap=plt.get_cmap('autumn_r'))\n",
    "    col_bar=plt.colorbar(im)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    col_bar.set_label('Intensity dB')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    min_intensity = col_bar.vmin\n",
    "    save.append(min_intensity)\n",
    "    #maximum intensity\n",
    "    max_intensity = col_bar.vmax\n",
    "    save.append(max_intensity)\n",
    "    #mean intensity\n",
    "    mean_intensity = (min_intensity + max_intensity) / 2\n",
    "    save.append(mean_intensity)\n",
    "\n",
    "    sound = AudioSegment.from_wav(os.path.join(files_dir,file))\n",
    "    len(sound)\n",
    "    chunks = split_on_silence(sound, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=20,\n",
    "\n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "        silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # 1000 means 1 sec then 60 second means\n",
    "    sixty_seconds = 60 * 1000\n",
    "\n",
    "    second_1_minute = sound[sixty_seconds:120000]\n",
    "    hunks = split_on_silence(second_1_minute, \n",
    "        # must be silent for at least half a second\n",
    "        min_silence_len=20,\n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS\n",
    "        silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "    )\n",
    "\n",
    "    #SPEAKING RATE\n",
    "    speaking_rate=len(hunks)/len(chunks)\n",
    "    save.append(speaking_rate)\n",
    "    \n",
    "    #SILENCES\n",
    "    pauses=detect_silence(sound, min_silence_len=20, silence_thresh=-(round(abs(sound.dBFS))+100), seek_step=1)\n",
    "    try:\n",
    "        save.append(pauses[0][1])\n",
    "    except:\n",
    "          save.append(0)\n",
    "    #FINDING DURATIONS\n",
    "    sumd=0\n",
    "    ls=[]\n",
    "    for start_i, end_i in pauses:\n",
    "            dur=int(end_i)-int(start_i)\n",
    "            ls.append(dur)\n",
    "    breaks=[]\n",
    "\n",
    "    #VOICE BREAKS\n",
    "    for i in ls:\n",
    "        if i >900:\n",
    "            breaks.append(i)\n",
    "    save.append(len(breaks))\n",
    "    #SEPRATING BREAKES AND PAUSES\n",
    "    ls=list(set(ls)-set(breaks))\n",
    "    #PUASES DURATION\n",
    "    for i in ls:\n",
    "        sumd=sumd+i\n",
    "    save.append(sumd)\n",
    "    #NO OF PAUSES\n",
    "    nop=len(ls)\n",
    "    save.append(nop)\n",
    "    #NO OF VOICE BREAKES\n",
    "    noofVoiceBreaks=len(breaks)\n",
    "    save.append(noofVoiceBreaks)\n",
    "    #MAXIMUM DURATION OF PAUSES\n",
    "    try:\n",
    "        maximum_pause=max(ls)\n",
    "    except:\n",
    "        maximum_pause=0\n",
    "    save.append(maximum_pause)\n",
    "    #AVG DURATION OF PAUSES\n",
    "    try:\n",
    "        avgp=sumd/nop\n",
    "    except:\n",
    "        avgp =0\n",
    "    save.append(avgp)\n",
    "    #FINDING PEAK\n",
    "    peak=scipy.signal.find_peaks(data,rel_height=0.5)\n",
    "    #MAXIMUM FALLING AND MAXIMUM RISING\n",
    "    MaxFalling=np.amin(data)\n",
    "    save.append(MaxFalling)\n",
    "    MaxRising=np.amax(peak[0])\n",
    "    save.append(MaxRising)\n",
    "\n",
    "    #JITTER, SHIMMER, JITTERRAP \n",
    "    sums=0\n",
    "    for i in range(1,len(peak[0])-1):\n",
    "        sums=sums+abs(20*math.log10(peak[0][i+1]/peak[0][i]))\n",
    "    #SHIMMER\n",
    "    shimmer=sums/(len(peak[0])-1)\n",
    "    peakf=abs(np.fft.fft(peak[0]))\n",
    "    sumps=0\n",
    "    for i in range(1,len(peakf)-1):\n",
    "        sumps=sumps+(peakf[i+1]**-1)-(peakf[i]**-1)\n",
    "\n",
    "    #JITTER\n",
    "    jitter=sumps/(len(peakf)-1)\n",
    "    sortedp=np.sort(peak[0])\n",
    "    sortedf=abs(np.fft.fft(sortedp))\n",
    "    dif=abs(sortedp[11]-sortedp[15])\n",
    "    suh=0\n",
    "    avgabsdiff=(dif)/4\n",
    "    avgneigh1=(abs(sortedp[6]-sortedp[10]))\n",
    "    avgneigh2=abs(sortedp[17]-sortedp[22])\n",
    "    avg=(dif+avgneigh1+avgneigh2)/3\n",
    "\n",
    "    for i in range(11,16):\n",
    "        suh=suh+abs(sortedf[i]**-1)\n",
    "    period=suh/5\n",
    "\n",
    "    #JITTERRAP\n",
    "    jitterrap=(avgabsdiff+avg)/period\n",
    "\n",
    "    save.append(jitter)\n",
    "    save.append(shimmer)\n",
    "    save.append(jitterrap)\n",
    "    \n",
    "    #NUMBER OF RISING, NUMBER OF FALLING, AVERAGE RISE, AVERAGE FALL\n",
    "\n",
    "    noofrise=len(peak[0])\n",
    "    \n",
    "    avgtorise=noofrise/len(data)\n",
    "    nooffall=0\n",
    "    for i in data:   \n",
    "        if i == np.amin(data):\n",
    "            nooffall=nooffall+1\n",
    "\n",
    "    avgtofall=nooffall/len(data)\n",
    "    save.append(noofrise)\n",
    "    save.append(nooffall)\n",
    "    save.append(avgtorise)\n",
    "    save.append(avgtofall)\n",
    "\n",
    "    # ZCR\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    save.append(zcr[0]) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    save.append(rms[0]) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(mel)) # stacking horizontally\n",
    "\n",
    "    # Spectral Bandwidth\n",
    "    sb = np.mean(librosa.feature.spectral_bandwidth(y=data,sr=16000), axis=0)\n",
    "    save.append(np.mean(mel))\n",
    "\n",
    "    # Spectral Centroid\n",
    "    sc = np.mean(librosa.feature.spectral_centroid(y=data,sr=16000), axis=0)\n",
    "    save.append(np.mean(mel))\n",
    "    df.loc[len(df)] = save\n",
    "    save = []\n",
    "    print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"statistic data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "save = []\n",
    "for index,file in enumerate(os.listdir(files_dir)[5000:5500]):\n",
    "    save.append(file[:-4])\n",
    "    save.append(label_df[\"professional-diagnosis\"].loc[label_df[\"file_name\"]==file].values[0])\n",
    "    data, sampling_rate  = librosa.core.load(os.path.join(files_dir,file))\n",
    "    Audio(data = data,rate = sampling_rate)\n",
    "    librosa.display.waveshow(data, sampling_rate)\n",
    "    # Duration : Total duration of the audio\n",
    "    total_samples = data.size\n",
    "    total_duration = int(total_samples/sampling_rate)\n",
    "    save.append(total_duration)\n",
    "    # Fourier Transform from data \n",
    "\n",
    "    fourier_transform = np.fft.rfft(data)\n",
    "\n",
    "    # Frequencies\n",
    "\n",
    "    frequencies = np.abs(fourier_transform)\n",
    "    \n",
    "    # Maximum Pitch\n",
    "\n",
    "    max_pitch = np.argmax(frequencies)\n",
    "    save.append(max_pitch)\n",
    "\n",
    "    arr = [117]*len(frequencies)\n",
    "    sum_freq = 0\n",
    "    for i in range(0,len(frequencies)):\n",
    "        if int(frequencies[i])>0 and int(frequencies[i])<int(max_pitch):\n",
    "            arr[i] = int(frequencies[i])\n",
    "            sum_freq=sum_freq + i\n",
    "    # Minmum Pitch\n",
    "    min_pitch = arr.index(min(arr))\n",
    "    save.append(min_pitch)\n",
    "    # Mean pitch\n",
    "    mean_pitch=sum_freq/len(frequencies)\n",
    "    save.append(mean_pitch)\n",
    "    #total energy\n",
    "    energy= np.sum(data**2)\n",
    "    save.append(energy)\n",
    "    energy_freq = np.sum(frequencies**2)/total_samples\n",
    "    save.append(energy_freq)\n",
    "    #power\n",
    "    power = energy / total_duration\n",
    "    save.append(power)\n",
    "    #minimum intensity\n",
    "    plt.figure(1, figsize=(9,6))\n",
    "    plt.subplot(211)\n",
    "    #IntensityMin : Minimum Intensity of the audio signal\n",
    "    Pxx, freqs, bins, im = plt.specgram(data, Fs = sampling_rate, NFFT=1024, cmap=plt.get_cmap('autumn_r'))\n",
    "    col_bar=plt.colorbar(im)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    col_bar.set_label('Intensity dB')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    min_intensity = col_bar.vmin\n",
    "    save.append(min_intensity)\n",
    "    #maximum intensity\n",
    "    max_intensity = col_bar.vmax\n",
    "    save.append(max_intensity)\n",
    "    #mean intensity\n",
    "    mean_intensity = (min_intensity + max_intensity) / 2\n",
    "    save.append(mean_intensity)\n",
    "\n",
    "    sound = AudioSegment.from_wav(os.path.join(files_dir,file))\n",
    "    len(sound)\n",
    "    chunks = split_on_silence(sound, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=20,\n",
    "\n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "        silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # 1000 means 1 sec then 60 second means\n",
    "    sixty_seconds = 60 * 1000\n",
    "\n",
    "    second_1_minute = sound[sixty_seconds:120000]\n",
    "    hunks = split_on_silence(second_1_minute, \n",
    "        # must be silent for at least half a second\n",
    "        min_silence_len=20,\n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS\n",
    "        silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "    )\n",
    "\n",
    "    #SPEAKING RATE\n",
    "    speaking_rate=len(hunks)/len(chunks)\n",
    "    save.append(speaking_rate)\n",
    "    \n",
    "    #SILENCES\n",
    "    pauses=detect_silence(sound, min_silence_len=20, silence_thresh=-(round(abs(sound.dBFS))+100), seek_step=1)\n",
    "    try:\n",
    "        save.append(pauses[0][1])\n",
    "    except:\n",
    "          save.append(0)\n",
    "    #FINDING DURATIONS\n",
    "    sumd=0\n",
    "    ls=[]\n",
    "    for start_i, end_i in pauses:\n",
    "            dur=int(end_i)-int(start_i)\n",
    "            ls.append(dur)\n",
    "    breaks=[]\n",
    "\n",
    "    #VOICE BREAKS\n",
    "    for i in ls:\n",
    "        if i >900:\n",
    "            breaks.append(i)\n",
    "    save.append(len(breaks))\n",
    "    #SEPRATING BREAKES AND PAUSES\n",
    "    ls=list(set(ls)-set(breaks))\n",
    "    #PUASES DURATION\n",
    "    for i in ls:\n",
    "        sumd=sumd+i\n",
    "    save.append(sumd)\n",
    "    #NO OF PAUSES\n",
    "    nop=len(ls)\n",
    "    save.append(nop)\n",
    "    #NO OF VOICE BREAKES\n",
    "    noofVoiceBreaks=len(breaks)\n",
    "    save.append(noofVoiceBreaks)\n",
    "    #MAXIMUM DURATION OF PAUSES\n",
    "    try:\n",
    "        maximum_pause=max(ls)\n",
    "    except:\n",
    "        maximum_pause=0\n",
    "    save.append(maximum_pause)\n",
    "    #AVG DURATION OF PAUSES\n",
    "    try:\n",
    "        avgp=sumd/nop\n",
    "    except:\n",
    "        avgp =0\n",
    "    save.append(avgp)\n",
    "    #FINDING PEAK\n",
    "    peak=scipy.signal.find_peaks(data,rel_height=0.5)\n",
    "    #MAXIMUM FALLING AND MAXIMUM RISING\n",
    "    MaxFalling=np.amin(data)\n",
    "    save.append(MaxFalling)\n",
    "    MaxRising=np.amax(peak[0])\n",
    "    save.append(MaxRising)\n",
    "\n",
    "    #JITTER, SHIMMER, JITTERRAP \n",
    "    sums=0\n",
    "    for i in range(1,len(peak[0])-1):\n",
    "        sums=sums+abs(20*math.log10(peak[0][i+1]/peak[0][i]))\n",
    "    #SHIMMER\n",
    "    shimmer=sums/(len(peak[0])-1)\n",
    "    peakf=abs(np.fft.fft(peak[0]))\n",
    "    sumps=0\n",
    "    for i in range(1,len(peakf)-1):\n",
    "        sumps=sumps+(peakf[i+1]**-1)-(peakf[i]**-1)\n",
    "\n",
    "    #JITTER\n",
    "    jitter=sumps/(len(peakf)-1)\n",
    "    sortedp=np.sort(peak[0])\n",
    "    sortedf=abs(np.fft.fft(sortedp))\n",
    "    dif=abs(sortedp[11]-sortedp[15])\n",
    "    suh=0\n",
    "    avgabsdiff=(dif)/4\n",
    "    avgneigh1=(abs(sortedp[6]-sortedp[10]))\n",
    "    avgneigh2=abs(sortedp[17]-sortedp[22])\n",
    "    avg=(dif+avgneigh1+avgneigh2)/3\n",
    "\n",
    "    for i in range(11,16):\n",
    "        suh=suh+abs(sortedf[i]**-1)\n",
    "    period=suh/5\n",
    "\n",
    "    #JITTERRAP\n",
    "    jitterrap=(avgabsdiff+avg)/period\n",
    "\n",
    "    save.append(jitter)\n",
    "    save.append(shimmer)\n",
    "    save.append(jitterrap)\n",
    "    \n",
    "    #NUMBER OF RISING, NUMBER OF FALLING, AVERAGE RISE, AVERAGE FALL\n",
    "\n",
    "    noofrise=len(peak[0])\n",
    "    \n",
    "    avgtorise=noofrise/len(data)\n",
    "    nooffall=0\n",
    "    for i in data:   \n",
    "        if i == np.amin(data):\n",
    "            nooffall=nooffall+1\n",
    "\n",
    "    avgtofall=nooffall/len(data)\n",
    "    save.append(noofrise)\n",
    "    save.append(nooffall)\n",
    "    save.append(avgtorise)\n",
    "    save.append(avgtofall)\n",
    "\n",
    "    # ZCR\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    save.append(zcr[0]) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    save.append(rms[0]) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=16000).T, axis=0)\n",
    "    save.append(np.mean(mel)) # stacking horizontally\n",
    "\n",
    "    # Spectral Bandwidth\n",
    "    sb = np.mean(librosa.feature.spectral_bandwidth(y=data,sr=16000), axis=0)\n",
    "    save.append(np.mean(mel))\n",
    "\n",
    "    # Spectral Centroid\n",
    "    sc = np.mean(librosa.feature.spectral_centroid(y=data,sr=16000), axis=0)\n",
    "    save.append(np.mean(mel))\n",
    "    df.loc[len(df)] = save\n",
    "    save = []\n",
    "    print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"statistic_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "633bf2759fc0a7f4cda3481845fe7ea6530e49a0cd0358cdd14e096add1492c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
